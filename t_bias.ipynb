{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from q8_gemm import q8_mm, q8_mm_bias\n",
    "from fast_hadamard_transform import hadamard_transform\n",
    "\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "def hadamard_quant(x):\n",
    "    k = x.shape[-1]\n",
    "    x_hadamard = hadamard_transform(x, scale=1/math.sqrt(k))\n",
    "    x_abs_max_hadamard = x_hadamard.float().abs().max(-1, False).values\n",
    "    x_scale_hadamard = x_abs_max_hadamard/127.0\n",
    "    x_q8_hadamard = (x_hadamard.float() / x_scale_hadamard[..., None]).round().to(torch.int8)\n",
    "    return x_q8_hadamard, x_scale_hadamard\n",
    "\n",
    "def quant(x):\n",
    "    x_abs_max = x.float().abs().max(-1, False).values\n",
    "    x_scale = x_abs_max/127.0\n",
    "    x_q8 =  (x.float() / x_scale[..., None]).round().to(torch.int8)\n",
    "    return x_q8, x_scale\n",
    "\n",
    "\n",
    "l_idx = 3\n",
    "x = torch.load(f\"/data/LTXVideo/acts/ffn/hs-{l_idx}.pt\", map_location=\"cuda\")[:, :, :]\n",
    "model_weights = load_file(\"/data/ltx_weights/unet/unet_diffusion_pytorch_model.safetensors\", device=\"cpu\")\n",
    "w = model_weights[f\"transformer_blocks.{l_idx}.ff.net.0.proj.weight\"].cuda()\n",
    "bias = model_weights[f\"transformer_blocks.{l_idx}.ff.net.0.proj.bias\"].cuda().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = x.shape[-1]\n",
    "x_hadamard = hadamard_transform(x.to(torch.float8_e4m3fn), scale=1/math.sqrt(k))\n",
    "w_hadamard = hadamard_transform(w.to(torch.float8_e4m3fn), scale=1/math.sqrt(k))\n",
    "\n",
    "x_quant_h, x_scales_h = hadamard_quant(x.to(torch.float8_e4m3fn))\n",
    "w_quant_h, w_scales_h = hadamard_quant(w.to(torch.float8_e4m3fn))\n",
    "\n",
    "x_quant, x_scales = quant(x)\n",
    "w_quant, w_scales = quant(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_q8_h = q8_mm_bias(x_quant_h, w_quant_h, bias, x_scales_h, w_scales_h, False)\n",
    "o_q8 = q8_mm_bias(x_quant, w_quant, bias, x_scales, w_scales, False)\n",
    "\n",
    "o_q8_torch_h = ((x_scales_h[..., None] * w_scales_h[None, None, :]) * torch.matmul(x_quant_h.float(), w_quant_h.float().t()) + bias[None, None, :]).to(torch.float8_e4m3fn)\n",
    "o_q8_torch = (((x_scales[..., None] * w_scales[None, None, :]) * torch.matmul(x_quant.float(), w_quant.float().t())) + bias[None, None, :]).to(torch.float8_e4m3fn)\n",
    "\n",
    "\n",
    "o_orig = torch.matmul(x.half(), w.half().t()) + bias[None, None, :].half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_max(a, b):\n",
    "    return (a.float() - b.float()).abs().max()\n",
    "\n",
    "def diff_mean(a, b):\n",
    "    return (a.float() - b.float()).abs().mean()\n",
    "\n",
    "\n",
    "def diff_quantiles(a, b):\n",
    "    if a.ndim > 2:\n",
    "        return torch.quantile((a.float() - b.float()).abs()[1, :2048, :], torch.tensor([0.25, 0.5, 0.75, 0.9, 0.99, 1.0]).cuda())\n",
    "    else:\n",
    "        return torch.quantile((a.float() - b.float()).abs()[:2048, :], torch.tensor([0.25, 0.5, 0.75, 0.9, 0.99, 1.0]).cuda())\n",
    "        \n",
    "diff_q8_h = diff_max(o_q8_h, o_orig)\n",
    "diff_q8 = diff_max(o_q8, o_orig)\n",
    "diff_q8_torch_h = diff_max(o_q8_torch_h, o_orig)\n",
    "diff_q8_torch = diff_max(o_q8_torch, o_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFF Hadamard:  tensor(0.5938, device='cuda:0')\n",
      "DIFF no Hadamard:  tensor(0.7031, device='cuda:0')\n",
      "DIFF Hadamard Torch:  tensor(0.5938, device='cuda:0')\n",
      "DIFF no Hadamard Torch:  tensor(0.7031, device='cuda:0')\n",
      "Diff mean hadamard:  tensor(0.5938, device='cuda:0')\n",
      "Diff mean:  tensor(0.7031, device='cuda:0')\n",
      "torch q8:  tensor(0.5000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"DIFF Hadamard: \", diff_q8_h)\n",
    "print(\"DIFF no Hadamard: \", diff_q8)\n",
    "\n",
    "print(\"DIFF Hadamard Torch: \", diff_q8_torch_h)\n",
    "print(\"DIFF no Hadamard Torch: \", diff_q8_torch)\n",
    "\n",
    "print(\"Diff mean hadamard: \", diff_max(o_orig, o_q8_h))\n",
    "print(\"Diff mean: \", diff_max(o_orig, o_q8))\n",
    "\n",
    "print(\"torch q8: \", diff_max(o_q8_torch_h, o_q8_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch q8:  tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2500], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"torch q8: \", diff_quantiles(o_q8_torch_h, o_q8_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27261435, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(o_q8_h.float() - o_q8_torch_h.float()).abs().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.5000, device='cuda:0', dtype=torch.float8_e4m3fn)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_q8_torch_h.flatten()[(o_q8_h.float() - o_q8_torch_h.float()).abs().argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5., device='cuda:0', dtype=torch.float8_e4m3fn)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_q8_h.flatten()[(o_q8_h.float() - o_q8_torch_h.float()).abs().argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.6914, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_orig.flatten()[(o_q8_h.float() - o_q8_torch_h.float()).abs().argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
